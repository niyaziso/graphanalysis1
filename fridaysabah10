import numpy as np
import funs as fs
import networkx as nx
import scipy.io as sio
import matplotlib.pyplot as plt
from networkx.algorithms import components
from collections import defaultdict
from operator import itemgetter
import time
import collections
tic = time.clock()
'from numpy import matrix'
'from exist_search import exist_search'
data = np.genfromtxt("EXTENDED_CARE.matrix", delimiter = ',')
m_subgraph = len(data[:,1]); n_subgraph = len(data[1,:]); 
perc_rate= 0.20; 
attempt_limit = 10; 
step_limit = 4;
th_graph_nodes = 4; 
new_data = data+1
subgraph_anomaly_list = np.genfromtxt("extendedcare_anomaly_list.txt"); 
subgraph_anomaly_list_len = int(len(subgraph_anomaly_list));
umatrix3 = np.unique(new_data); 
umatrix311 = np.matrix(new_data);
umatrix3_len = (len(umatrix3)); 
#portion20 = int(round(umatrix3_len*0.2)); 
#listofindx = (np.random.uniform(0,umatrix3_len,[portion20]));
train_sample_index = [];indmatrix = []; temp = 0; 
train_sample = [];
nonsample_set = []; 
#train_an=np.random.uniform(0,subgraph_anomaly_list_len,int(round(subgraph_anomaly_list_len*perc_rate)));
checkinglist=subgraph_anomaly_list;
G = nx.Graph(); 
count = defaultdict(int)
G.add_nodes_from(umatrix3);
for i in range(0,len(new_data)):
    edge_list = [(new_data[i,0], new_data[i,1])]
    G.add_edges_from(edge_list);
    count['components']+=1
  #  components = nx.connected_components(G)
node_and_degree=G.degree()

keys1 = node_and_degree.keys()
myList=node_and_degree.values()
sorteddegrees = sorted(myList, reverse = True)
index1 = [i[0] for i in sorted(enumerate(myList), key=lambda x:x[1], reverse = True)]
for i in index1:
    if myList[index1[i]]==th_graph_nodes:
        index_limit = i
        break
print index_limit
#(largest_hub,degree)=sorted(node_and_degree.items(),key=itemgetter(1))[-1]
#hub_ego=nx.ego_graph(G,largest_hub)
#pos=nx.spring_layout(hub_ego)
#nx.draw(hub_ego,pos,node_color='b',node_size=50,with_labels=False)
#nx.draw_networkx_nodes(hub_ego,pos,nodelist=[largest_hub],node_size=300,node_color='r')
dictlist = [];
for i in range(0,index_limit):
    dictlist.append([keys1[index1[i]],myList[index1[i]]])
dictlist1 = np.transpose(dictlist);
dictlist2 = dictlist1[1]
dictlist0 = dictlist1[0] 

Gnew = nx.Graph(); 
Gnew.add_nodes_from(dictlist0)
count1 = 0 
Gnewlist = []; 
for i1 in range(0,len(new_data)):
    edge_list = [new_data[i1,0], new_data[i1,1]]
    if ((edge_list[0] in dictlist0) or (edge_list[1] in dictlist0)):
        edge_list =[(new_data[i1,0], new_data[i1,1])]
        Gnewlist=np.append(Gnewlist,edge_list)
        Gnew.add_edges_from(edge_list);
        count1 = count1+1
        #count1['components']+=1
components = nx.connected_components(Gnew)
H=nx.connected_component_subgraphs(Gnew)

cleaned_amount = len(new_data)-len(Gnewlist)/2
num_con_com_clean = nx.number_connected_components(Gnew)
num_con_com_noisy = nx.number_connected_components(G)
noise_reduction_components = num_con_com_noisy-num_con_com_clean;
list_conc_nodes = nx.connected_components(Gnew)
list_conc_subgraphs = nx.connected_component_subgraphs(Gnew)
temp2 = nx.node_connected_component(Gnew, dictlist0[0])
temp2 = np.array(temp2[0])
ind_listi3 = np.array([]);lenind = ind_listi3;
for i3 in range(0,len(dictlist0)):
    list1 = nx.node_connected_component(Gnew, dictlist0[i3]) 
    list1 = sorted(list1)
    temp01 = len (list1)
    temp0 = list1[0]

    if temp0 not in temp2:
        temp2 = np.append(temp2,temp0) 
        ind_listi3 = np.append(ind_listi3,i3)
        lenind = np.append(lenind,(len(list1)))
        
max_subgroup_numofnodes = max(lenind);
temp3 = np.zeros([num_con_com_clean,max_subgroup_numofnodes]);
c1 = 0
for i4 in ind_listi3:
    list2 = nx.node_connected_component(Gnew, dictlist0[i4]) 
    temp3[c1,0:len(list2)] = list2
    c1+=1;
temp6 = np.zeros([num_con_com_clean,max_subgroup_numofnodes])
k1 = np.array([])

temp9 = np.empty([num_con_com_clean,max_subgroup_numofnodes])
for i5 in range(0,num_con_com_clean):
    temp4 = temp3[i5]
    temp7 = np.array([]);
    temp10 =temp6[i5];
    i6 = 0; count = 0  
    while i6 < int(lenind[i5])-1:
        i6 = i6 + 1
        temp5 = temp4[0:int(lenind[i5])]  
        temp7 = np.append(temp7, fs.checkanomaly(checkinglist,temp5[i6]))
    temp10[0:int(lenind[i5])-1] = temp7;
    temp9[i5] =  temp10
    k1 = np.append(k1, sum(temp10))
k2=sum(k1)
newk = np.zeros([int(max(k1))])
anomaly_list_concern = np.array([])
all_nodes = np.array([])
for i in range(0,num_con_com_clean):
    temp = temp9[i]
    tempp = temp3[i]
    for j in range(0, int(lenind[i])): 
        all_nodes = np.unique(np.append(all_nodes,tempp[j]))  
        if temp[j] == 1 : 
            anomaly_list_concern = np.append(anomaly_list_concern, tempp[j])
pnodes = int(round(perc_rate*(len(all_nodes))))
all_nodes_len = int(len(all_nodes))
training_nodesind = np.random.randint(0,all_nodes_len,pnodes);
nontrain_nodesind = np.array([])
anom_train_list=nontrain_nodesind
for i in range(0,all_nodes_len):
    if i not in training_nodesind:
        nontrain_nodesind = np.append(nontrain_nodesind,i)
training_set = np.array([]);nontrain_set = np.array([])
for i in training_nodesind:
    training_set = (np.append(training_set,umatrix3[i]))
for i in nontrain_nodesind:
    nontrain_set = (np.append(nontrain_set,umatrix3[i]))
for i in training_set:
    anom_val = fs.checkanomaly(anomaly_list_concern,i)
    if anom_val == 1 :
        anom_train_list = np.append(anom_train_list, i)
nonsamp_anom = (np.array([]))
for i in nontrain_set:
    anom_val = fs.checkanomaly(anomaly_list_concern,i)
    if anom_val == 1 :
        nonsamp_anom = (np.append(nonsamp_anom, i))
randomtrainingsetratio = len(training_set)/len(anom_train_list)

            
known_anomaly = nonsamp_anom;
training_set   # will be used
new_data1 = np.transpose(new_data);

#g1 = len(nonsamp_anom); 
#g2 = len(anom_train_list); 
matrix_gen = np.zeros([len(training_set),3]);
active_node_seq = np.array([]); 
c1 = 0 ;
check_anomaly_class = nonsamp_anom # select which anomaly class you choose for the estimation
for i in range(0,len(training_set)):# all training unique nodes which is 20 percent. 
    att = 0 ;
    active_node = training_set[i] 
    if (np.remainder(i, 1000)==1):
       print i
    while att < attempt_limit:
        temp122= np.array([])
        step_count = 0 
        if active_node in new_data1[0]:
            wh1 = np.where(new_data1[0]==active_node)
            temp12 = np.array([]); 
            for i55 in wh1 : 
                temp12=np.append(temp12,i55)
            k1 = len(temp12)

        if active_node in new_data1[1]:
            wh2 = np.where(new_data1[1]==active_node)
            temp13 = np.array([]); 
            for i55 in wh2 : 
                temp13=np.append(temp13,i55)
            k2 = len(temp13)
        if  int(len(k1)) == int(len(k2)) :
            num1 = np.random.randint(k2)
            res = temp13[num1-1]
            flag = 1 
        elif k1>k2:
            num1 = np.random.randint(k1)
            temp12 = np.array([]); 
            for i55 in wh1 : 
                temp12=np.append(temp12,i55)
            res = temp12[num1-1]
            flag = 0 
        elif k2>k1:
            num1 = np.random.randint(k2)
            for i55 in wh2 : 
                temp13=np.append(temp13,i55)
            res = temp13[num1-1]
            flag = 1 

        active_node = new_data1[flag][res] #new_data[wh1[0][r1], wh1[1][r1]]

            
      #  active_node = new_data[wh1[0][r1-1],wh1[1][r1-1]] #new_data[wh1[0][r1], wh1[1][r1]]
        active_node_seq = np.append(active_node_seq,active_node)
        matrix_gen[i,2] = fs.checkanomaly(check_anomaly_class,active_node) # anomaly original indicator last column
        flag_holder = np.array([])
        while len(active_node_seq)<step_limit:
            if flag == 1 :
                flag = 0 ; flag_holder = np.append(flag_holder,flag)
                active_node = new_data1[flag][res]# fs.otherside(wh1, new_data, r1)
            else : 
                flag = 1 ;flag_holder = np.append(flag_holder,flag)
                active_node = new_data1[flag][res]# fs.otherside(wh1, new_data, r1)
            if len(flag_holder) > 2:
                wh3 =np.where(new_data1[flag_holder[-1]]==active_node);
                temp13 = np.array([]); 
                for i55 in wh3: 
                    temp13=np.append(temp13,i55)
                k2 = len(temp13)
                num1 = np.random.randint(k2)
                res = temp13[num1-1]
            active_node = new_data1[flag_holder-2][res]
            active_node_seq = np.append(active_node_seq, active_node)
            #anomaly_res = fs.checkanomaly(check_anomaly_class,active_node_seq[-1]) # anomaly original indicator last column
            anomaly_res_indicator = fs.oneise(active_node,check_anomaly_class)
            matrix_gen[i,1] = matrix_gen[i,1] + anomaly_res_indicator
            matrix_gen[i,0] = matrix_gen[i,0] + 1
            if anomaly_res_indicator == 1:   
                break      
        att = att+1; 
        print att

toc = time.clock()  ; comp_time=toc - tic ; print comp_time   ## evaluate the computation time


#%%%%

